{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acting-things",
   "metadata": {},
   "source": [
    "### Exercise 1: Training a simple linear model\n",
    "\n",
    "We do not know how to create a full neural network yet, by we know how to optimize a model.\n",
    "We will try to solve a problem that consists in optimizing a simple model using an optimizer and the autograd.\n",
    "\n",
    "Here is the physical problem:\n",
    "\n",
    "* Let's consider a linear system characterized by a transmission matrix $\\mathbf{H}$ (real) of size `n_out` $\\times$ `n_in`.\n",
    "* We send a collection of `n_inputs` random inputs, reprenseted by a matrix $\\mathbf{X}$ of size `n_inputs` $\\times$ `n_in`.\n",
    "* We retrive the output corresponding to $\\mathbf{Y} = \\mathbf{X} \\times \\mathbf{H}^t$ of size `n_inputs` $\\times$ `n_out`.\n",
    "* We add a noise with a variance `noise_var` to $\\mathbf{Y}$.\n",
    "\n",
    "Because we know the system is fully described by a matrix $\\mathbf{H}$, we will use a **network** with only one layer corresponding to a **dense layer** (i.e. one matrix multiplication, the coefficients being the parameters to be trained. \n",
    "\n",
    "Using the above example, create and train the system to find the correct matrix that correctly predict $\\mathbf{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "athletic-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-vermont",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tribal-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the system matrix\n",
    "n_in, n_out = 6,10\n",
    "# number of random input we use to estimate the response of the system\n",
    "n_inputs = 25\n",
    "# noise level (relative to the signal)\n",
    "noise_var = 5e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-gardening",
   "metadata": {},
   "source": [
    "**Generate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "functioning-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transmission matrix\n",
    "H = np.random.randn(n_out, n_in)\n",
    "\n",
    "# inputs\n",
    "X = np.random.randn(n_inputs, n_in)\n",
    "\n",
    "# outputs\n",
    "Y = X@H.transpose() \n",
    "\n",
    "# noise\n",
    "noise = np.random.randn(*Y.shape)\n",
    "noise *= np.linalg.norm(Y)/np.linalg.norm(noise)*noise_var\n",
    "\n",
    "Y += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lightweight-inquiry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-rider",
   "metadata": {},
   "source": [
    "**Convert data to PyTorch on `device`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "manual-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pt = torch.from_numpy(X).to(device).type(torch.float)\n",
    "Y_pt = torch.from_numpy(Y).to(device).type(torch.float)\n",
    "H_pt = torch.from_numpy(H).to(device).type(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-hierarchy",
   "metadata": {},
   "source": [
    "**Model**\n",
    "\n",
    "A single dense layer (matrix multiplication).\n",
    "\n",
    "Not deep learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "severe-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(n_in, n_out).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-answer",
   "metadata": {},
   "source": [
    "**Loss function and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "global-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/py38/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# create loss function\n",
    "loss_fn = torch.nn.MSELoss(size_average=False) # Mean square error\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dominican-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0\t loss = 2.16e+03\n",
      "iteration = 5\t loss = 2.31e+01\n",
      "iteration = 10\t loss = 5.89e+00\n",
      "iteration = 15\t loss = 3.87e+00\n",
      "iteration = 20\t loss = 3.53e+00\n",
      "iteration = 25\t loss = 3.47e+00\n",
      "iteration = 30\t loss = 3.46e+00\n",
      "iteration = 35\t loss = 3.46e+00\n",
      "iteration = 40\t loss = 3.46e+00\n",
      "iteration = 45\t loss = 3.46e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for iteration in range(50):\n",
    "    Y_pred = model(X_pt)\n",
    "    loss = loss_fn(Y_pred,Y_pt)\n",
    "    \n",
    "    optimizer.zero_grad() # before the backpropagation!   \n",
    "    # backward propagation done by autograd\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iteration % 5 == 0:\n",
    "        print(f\"iteration = {iteration}\\t loss = {loss.item():.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-companion",
   "metadata": {},
   "source": [
    "**Retrieve the estimater matrix and show the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "colonial-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_hat = model.weight.detach().cpu().numpy()\n",
    "# use detach() to remove the tracking of gradient, do it once the calculation is done\n",
    "# cpu() to copy it back to the cpu memory from the GPU\n",
    "# numpy() to covert PyTorch tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "irish-banner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Estiamte matrix')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEICAYAAAAA3gw5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT/UlEQVR4nO3deZRcdZnG8edJx6wdDJtgEmQXiTAncdoAsgyiDhJAnKOMqIBBMc4AEhyURY/IuM3iQvSIMjFqUFEGwUHloOgMoIISDYsHQ0AwCWQhIQFDFpCQ5J0/6sZTaXupJu+vqrvz/ZxT53Tduv3W211vPXXr1nIdEQIAbL8hrW4AAAYLAhUAkhCoAJCEQAWAJAQqACQhUAEgCYHaINvH2l7a6j7q2V5ve79W94HWsH207Yda3Ud/Yfsq2x9tZQ+DLlBtL7b9bBU2K2zPsd3e6r76wvbtts/ubb2IaI+Ihc3oCXk6zejW05ca+L2wfcDW8xHxy4g4qFCPc2x/skTtvrI9zfYdva0XEf8UEZ9oRk/dGXSBWjk5ItolTZI0WdKlrW0nl+2hre4B2+3k6gFx6+m8Vjc0kNlua3UP0uANVElSRKyQdItqwSpJsn247V/ZXmP7d7aPrbvsLNsLbK+zvdD2+xq9rmrr4RzbD1e//wnb+9v+te21tq+zPaxad2fbN9leZftP1c8Tqss+JeloSV+q33Kp6p9r+2FJD9ctO8D2MNv32X5/tbzN9p22L9u+/yCarbo9f277adurbf93tfwX1Sq/q+bibZ13Q9m+xPYfq/l7wPY/1F02rZqJK6rZX2j7NdXyJbafsP2uat3pkt4p6aLqun5ULR9n+4ZqbhfZPr+Hv2OO7S/b/nFV407be9qeWc38g7Yn99a77YMlXSXpiKrOmrr6X7F9s+0Nkl5bv1Vt+2Lbd23d+LD9z7bn2x6x3TdSTyJiUJ0kLZb0+urnCZLul/SF6vx4SU9Kmqrag8kbqvO7V5efKGl/SZb0d5KekfSq6rJjJS3t4XpD0g8l7STplZKek/R/kvaT9GJJD0h6V7XurpLeImmUpDGSvifpxrpat0s6u4v6P5O0i6SRdcsOqH4+RNKfJB0s6SOS7pLU1urbg1PPM9rFZd+tbr8hkkZIOqrTDBxQd36bmZR0qqRx1e++TdIGSS+tLpsmaZOksyS1SfqkpMckXSlpuKS/l7ROUnu1/hxJn6yrPUTS3ZIukzSsmuuFko7v5u+YI2m1pL+t/o5bJS2SdGbd9d/Wh97v6KL+05KOrPtf/aXnatkvJF0u6cDqvjG5+G3b6uEqNKzrq+GIKtTGVpddLOlbnda/RVXQdVHrRkkzuhreLtYNSUfWnb9b0sV15z8naWY3vztJ0p/qzt+urgP1uC6W1d/BLpT0YDU8B7b6tuDU64yuqTu9t7rsm5JmSZrQzYx1G6hdrH+fpFOqn6dJerjuskOrenvULXtS0qTq57+EU3X+MEmPdap/qaRvdHPdcyR9te78+yUt6HT9a/rQe1eB+s0ultX3vI+kpyQtkHRpM27bwfqU/80RMUa1gXuFpN2q5XtLOrV6yrOmevpwlKSXSpLtE6qnCU9Vl02t+91GrKz7+dkuzrdX1zPK9n/ZftT2WtUeScc2sB9oSS+XX63aEN0cEQ/3oW8035sjYmzd6avV8otUe4b0m+op6rsbLWj7zGrXz9bZPkTbzm/neVREdDmjXdhb0rhO950PS9qjh5Yauj802HtXerw/RMRiSbepdp+4spdaKQZroEqSIuLnqj1qfbZatES1LdT6QR4dEf9ue7ikG6p194iIsZJuVm24s10o6SBJh0XETpKOqZZvva7uvgKst68G+7KkmyQdb/uo7e4STRcRKyLivRExTtL7JH3Zda/sd8f23pK+Kuk8SbtW8/t7vfD57TxrSyQt6nTfGRMRU19g/b9ooPcXdH+wPVXSEao9S/3M9vbZiEEdqJWZkt5ge5Kkb0s62fbx1Qs3I6od+xNU2y80XNIqSZtsn6DafqUSxqj2CL3G9i6SPtbp8pWq7aNqmO0zVNtfNU3S+ZKu9gB7uxgk26dufYFStV03IWlzdb6nuRhdrbuqqnOWalt5L1Tn6/qNpLXViz0jq/vPIbZfvR3XsVVvva+UNMHVi7qNsL2bpK9JOlvSu1S73293+Pdm0AdqRKxSbb/URyNiiaRTVHuqskq1R90PSRoSEetUC6LrVBvkd6j2IlMJMyWNVG2n/V2SftLp8i9Iemv1augXeytm+2VVzTMjYn1EfEfSPElXZDaNVD/ytu9D/Z9q+aslzbW9XrX5mxERi6rLLlftgXKN7X+sLxYRD6i2n/7XqgXQoZLu3I7+viZpYnVdN0bEZkknq7a/f5FqsztbtRdct0sDvd8qab6kFbZXN1h2lqQfRMTNEfGkpPdImm171+3ttyeudt4CALbToN9CBYBmIVABIAmBCgBJCFQASFLkSzaGjhgdw9t3Sa8bJd4RKmnPPZ9Kr7ls/c7pNSVp7/Yni9R9dEP+7bVp1RptXreh0K3WfMXmutBmzbg98mdlyfr8v1+S9m5v9MX7vnl0Q5kX9TcuWr46InbvvLxIoA5v30UTT/xAet1NI9NLSpIu/uB38mvecWp6TUn64jFXF6l7ztzT02su+0hTPpzSNMPbd9HEk/Ln+vlR6SUlSZdd+K30mv9y59vSa0rSlUfPKVJ3+q/PLFJ38Ts/8mhXy3nKDwBJCFQASEKgAkASAhUAkhCoAJCEQAWAJA0Fqu032n7I9iO2LyndFNAMzDWy9Rqo1bfIXynpBEkTJb3d9sTSjQElMdcooZEt1CmSHomIhRGxUdK1qn2nKDCQMddI10igjte2x25ZWi3bhu3ptufZnrfpzxuy+gNKYa6RrpFA7eqz2H/1rdQRMSsiOiKiY+iI0dvfGVAWc410jQTqUkl71Z2fIGl5mXaApmGuka6RQP2tpANt71sdJOs0lTvWEtAszDXS9fptUxGxyfZ5km6R1Cbp6xExv3hnQEHMNUpo6Ov7IuJm1Y5RDwwazDWy8UkpAEhCoAJAEgIVAJIQqACQhEAFgCSO+KsPh2y34fuNj3GfODe97ktuHp5eU5L+vHP+48r+b/9Dek1JOnSnMu89P2L0w+k1zz9lkf5w/7OD5qinpeb6pTcOS68pSc/snj/XLz/jofSaknTImDJz/dr2B4rUPWbfhXdHREfn5WyhAkASAhUAkhCoAJCEQAWAJAQqACQhUAEgCYEKAEkIVABIQqACQBICFQCSEKgAkIRABYAkBCoAJCFQASAJgQoASQhUAEhCoAJAEgIVAJIQqACQhEAFgCQEKgAkGVqiqIeEho98Pr3uE1PKHPX0oydcn17z9aMWpteUpIuWnFyk7qqNY9Jrrtm8Mr1mKw0ZEhoxamN63cePKjPX/3niNek1DxtR5uiklyw9qUjd1c+3F6krdX3/ZgsVAJIQqACQhEAFgCQEKgAkIVABIAmBCgBJCFQASNJroNrey/ZtthfYnm97RjMaA0pjtpGtkTf2b5J0YUTcY3uMpLtt/ywiHijcG1Aas41UvW6hRsTjEXFP9fM6SQskjS/dGFAas41sfdqHansfSZMlze3isum259met/npZ5LaA5qju9mun+tNa5lr9KzhQLXdLukGSRdExNrOl0fErIjoiIiOthePyuwRKKqn2a6f66E7MdfoWUOBavtFqg3cNRHx/bItAc3DbCNTI6/yW9LXJC2IiM+XbwloDmYb2RrZQj1S0hmSjrN9X3WaWrgvoBmYbaTq9W1TEXGHJDehF6CpmG1k45NSAJCEQAWAJAQqACQhUAEgSZGD9L181CrdNOWq9Lrn7P7W9JqS9Jmr8+vO3JBeUpJ03YWfKVL33x5/Y3rNLTG4Xu85aPRq/XTKrPS65+1Z5sCLl88+Pb3mkPxjFEqSrr3gs0Xqfn7lG4rU7Q5bqACQhEAFgCQEKgAkIVABIAmBCgBJCFQASEKgAkASAhUAkhCoAJCEQAWAJAQqACQhUAEgCYEKAEkIVABIQqACQBICFQCSEKgAkIRABYAkBCoAJCFQASAJgQoASYoc9fShp/fUMT+akV73FROXpNeUpM0jI73msweVOTzkqfeeXaTuMw+OTa+5bt3P0mu20oI1e2jKD/PnetKhC9NrStLz7flzvfFlZeb69PunFam7dsGuRep2hy1UAEhCoAJAEgIVAJIQqACQhEAFgCQEKgAkIVABIEnDgWq7zfa9tm8q2RDQTMw1MvVlC3WGpAWlGgFahLlGmoYC1fYESSdKml22HaB5mGtka3QLdaakiyRt6W4F29Ntz7M9b/P69Rm9AaXNFHONRL0Gqu2TJD0REXf3tF5EzIqIjojoaGtvT2sQKIG5RgmNbKEeKelNthdLulbScba/XbQroDzmGul6DdSIuDQiJkTEPpJOk3RrRJxevDOgIOYaJfA+VABI0qfvQ42I2yXdXqQToEWYa2RhCxUAkhCoAJCEQAWAJAQqACQhUAEgSZGjnmqL5OecXvbQscvTa0rSe067I73m5bPLvKWxfVGZm+ysy3+cXvOKbz6dXrOlQtKm/Lk+cMyq9JqS9M7T5qbXLDXXIxeWmet3f7zMl4id/6Gul7OFCgBJCFQASEKgAkASAhUAkhCoAJCEQAWAJAQqACQhUAEgCYEKAEkIVABIQqACQBICFQCSEKgAkIRABYAkBCoAJCFQASAJgQoASQhUAEhCoAJAEgIVAJIQqACQpMyhBttCW3balF72urlT0mtK0qJDdk2vefSp96TXlKRb7pxUpO4FOy9Or/mdto3pNVtqSChGbE4v+71fHZZeU5KWTR6bXrPYXN8xqUjdc8cuKVL3/G6Ws4UKAEkIVABIQqACQBICFQCSEKgAkIRABYAkBCoAJGkoUG2PtX297QdtL7B9ROnGgGZgtpGp0Tf2f0HSTyLirbaHSRpVsCegmZhtpOk1UG3vJOkYSdMkKSI2ShpkH4HBjojZRrZGnvLvJ2mVpG/Yvtf2bNujO69ke7rtebbnbV6/Ib1RoIBeZ3ubuV7HXKNnjQTqUEmvkvSViJgsaYOkSzqvFBGzIqIjIjra2v8qb4H+qNfZ3mauxzDX6FkjgbpU0tKImFudv161IQQGOmYbqXoN1IhYIWmJ7YOqRa+T9EDRroAmYLaRrdFX+d8v6ZrqVdCFks4q1xLQVMw20jQUqBFxn6SOsq0AzcdsIxOflAKAJAQqACQhUAEgCYEKAEkIVABIUuaop1ssP9OWXnbYns+k15SkZzYNS695+G6/S68pScsnv7hI3YtXTkqvuXTTk+k1W2qL5efyt0FetMez6TUlac3Gkek137Tbvek1JemJjvYidT+88m+K1JUe6XIpW6gAkIRABYAkBCoAJCFQASAJgQoASQhUAEhCoAJAEgIVAJIQqACQhEAFgCQEKgAkIVABIAmBCgBJCFQASEKgAkASAhUAkhCoAJCEQAWAJAQqACQhUAEgSZmD9IXU9uf8rB5/Vf7B9CRp1Mc3pte8/H/fkl5Tknb/TZnHwHMuuzW95g+GlDn4XMuENKTAQfr2+kqZu2H7p55Lr3nJLael15Skl9zlInXP/tdfFqn7H90sZwsVAJIQqACQhEAFgCQEKgAkIVABIAmBCgBJCFQASNJQoNr+gO35tn9v+7u2R5RuDCiNuUa2XgPV9nhJ50vqiIhDJLVJKvPuXqBJmGuU0OhT/qGSRtoeKmmUpOXlWgKahrlGql4DNSKWSfqspMckPS7p6Yj4aef1bE+3Pc/2vC3rN+R3CiR6IXO9eQNzjZ418pR/Z0mnSNpX0jhJo22f3nm9iJgVER0R0TGkfXR+p0CiFzLXbaOZa/Sskaf8r5e0KCJWRcTzkr4v6TVl2wKKY66RrpFAfUzS4bZH2bak10laULYtoDjmGuka2Yc6V9L1ku6RdH/1O7MK9wUUxVyjhIa+iDEiPibpY4V7AZqKuUY2PikFAEkIVABIQqACQBICFQCSEKgAkKTI4RaHj9qo/TseS6+76o8vS68pSUuXjU+vOfP4b6XXlKRP7ze1SN3PHfDK9JorYkV6zVYaOfo5TZyyKL3u0j/um15TkpYtz5/rq074enpNSbps/1OK1L3igIOL1JXmd7mULVQASEKgAkASAhUAkhCoAJCEQAWAJAQqACQhUAEgCYEKAEkIVABIQqACQBICFQCSEKgAkIRABYAkBCoAJCFQASAJgQoASQhUAEhCoAJAEgIVAJIQqACQhEAFgCSOiPyi9ipJjzaw6m6SVqc3UM5A6rc/9Lp3ROze4h7S9GGupf7x/++LgdRvf+i1y9kuEqiNsj0vIjpa1kAfDaR+B1Kvg9FA+/8PpH77c6885QeAJAQqACRpdaDOavH199VA6ncg9ToYDbT//0Dqt9/22tJ9qAAwmLR6CxUABg0CFQCStCxQbb/R9kO2H7F9Sav66I3tvWzfZnuB7fm2Z7S6p0bYbrN9r+2bWt3LjobZLqe/z3VLAtV2m6QrJZ0gaaKkt9ue2IpeGrBJ0oURcbCkwyWd2497rTdD0oJWN7GjYbaL69dz3aot1CmSHomIhRGxUdK1kk5pUS89iojHI+Ke6ud1qt2Y41vbVc9sT5B0oqTZre5lB8RsFzIQ5rpVgTpe0pK680vVj2/IrWzvI2mypLktbqU3MyVdJGlLi/vYETHb5cxUP5/rVgWqu1jWr9+/Zbtd0g2SLoiIta3upzu2T5L0RETc3epedlDMdgEDZa5bFahLJe1Vd36CpOUt6qVXtl+k2sBdExHfb3U/vThS0ptsL1bt6eZxtr/d2pZ2KMx2GQNirlvyxn7bQyX9QdLrJC2T9FtJ74iI+U1vphe2LelqSU9FxAUtbqdPbB8r6YMRcVKLW9lhMNvl9ee5bskWakRsknSepFtU2xF+XX8cuMqRks5Q7RHxvuo0tdVNoX9itndsfPQUAJLwSSkASEKgAkASAhUAkhCoAJCEQAWAJAQqACQhUAEgyf8DqXKvz2fsb2MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(H)\n",
    "plt.title('Real matrix')\n",
    "plt.subplot(122)\n",
    "plt.imshow(H_hat)\n",
    "plt.title('Estiamte matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-premiere",
   "metadata": {},
   "source": [
    "### Exercice 2: Fully connected classifier for MNIST dataset\n",
    "\n",
    "\n",
    "<br>\n",
    "<center><figure>\n",
    "    <img src='img/dense_net.svg' alt='missing'/>\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complimentary-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "device  = device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nutritional-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\"./\", train=True, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                             target_transform=None, \n",
    "                             download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_test = datasets.MNIST(\"./\", train=False, \n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                             target_transform=None, \n",
    "                             download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "standard-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 350 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test( model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('>> Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smoking-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300672\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.624926\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.519737\n",
      ">> Test set: Average loss: 0.6849, Accuracy: 47870/60000 (79.8%)\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.701207\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.676404\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.187973\n",
      ">> Test set: Average loss: 0.3039, Accuracy: 54622/60000 (91.0%)\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.509816\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.310495\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.148266\n",
      ">> Test set: Average loss: 0.2424, Accuracy: 55710/60000 (92.8%)\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.251572\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.087974\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.466239\n",
      ">> Test set: Average loss: 0.1956, Accuracy: 56591/60000 (94.3%)\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.232700\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.273678\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.135543\n",
      ">> Test set: Average loss: 0.1655, Accuracy: 57106/60000 (95.2%)\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.104197\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.138999\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.109209\n",
      ">> Test set: Average loss: 0.1383, Accuracy: 57594/60000 (96.0%)\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.077209\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.177886\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.102093\n",
      ">> Test set: Average loss: 0.1218, Accuracy: 57844/60000 (96.4%)\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.245144\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.074041\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.133653\n",
      ">> Test set: Average loss: 0.1083, Accuracy: 58112/60000 (96.9%)\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.131525\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.127929\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.208629\n",
      ">> Test set: Average loss: 0.0962, Accuracy: 58317/60000 (97.2%)\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.053779\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.141463\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.164967\n",
      ">> Test set: Average loss: 0.0853, Accuracy: 58557/60000 (97.6%)\n"
     ]
    }
   ],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features = 28*28, out_features = 300)\n",
    "        self.fc2 = nn.Linear(in_features = 300, out_features = 200)\n",
    "        self.fc3 = nn.Linear(in_features = 200, out_features = 100)\n",
    "        self.fc4 = nn.Linear(in_features = 100, out_features = 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "model = DenseNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-leave",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
